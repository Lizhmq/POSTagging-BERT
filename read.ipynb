{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('py37': conda)"
  },
  "interpreter": {
   "hash": "522e9b59309082b50c0b134136edaad159791fc286ed2b2b087ebc2263c28895"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, random\n",
    "from utils import get_sent, get_label, get_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/Data1_train_utf16.tag\", \"r\", encoding=\"utf-16\") as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random.sample(data, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "empty_cnt = 0\n",
    "xs, ys, sts, ends = [], [], [], []\n",
    "for line in data:\n",
    "    sent, label = get_sent(line), get_label(line)\n",
    "    st, end = get_se(sent, 300)\n",
    "    if len(sent) == 0:\n",
    "        empty_cnt += 1\n",
    "        continue\n",
    "    xs.append(sent)\n",
    "    ys.append(label)\n",
    "    sts.append(st)\n",
    "    ends.append(end)\n",
    "print(empty_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "36227"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_data(file, x, y, st, end):\n",
    "    with open(file, \"wb\") as f:\n",
    "        pickle.dump({\"x\": x, \"y\": y,\n",
    "                    \"start\": st, \"end\": end}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_data(\"data/whole_train1.pkl\", xs, ys, sts, ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"../gan-codebert/data/inputs.pkl\", \"rb\") as f:\n",
    "#     inputs, labels = pickle.load(f)\n",
    "train_rate = 0.7\n",
    "valid_rate = 0.8\n",
    "train_l = int(train_rate * len(xs))\n",
    "validl = int(valid_rate * len(xs))\n",
    "trainx, trainy, trainst, trainend = xs[:train_l], ys[:train_l], sts[:train_l], ends[:train_l]\n",
    "validx, validy, validst, validend = xs[train_l:validl], ys[train_l:validl], sts[train_l:validl], ends[train_l:validl]\n",
    "testx, testy, testst, testend = xs[validl:], ys[validl:], sts[validl:], ends[validl:]\n",
    "dump_data(\"data/train1.pkl\", trainx, trainy, trainst, trainend)\n",
    "dump_data(\"data/valid1.pkl\", validx, validy, validst, validend)\n",
    "dump_data(\"data/test1.pkl\", testx, testy, testst, testend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['海內外/Nl',\n",
       " '關注/Vt',\n",
       " '的/Us',\n",
       " '一九九七/Mo',\n",
       " '年/Qc',\n",
       " '七月/Nt',\n",
       " '一/Mo',\n",
       " '日/Qc',\n",
       " '終於/Dc',\n",
       " '來到/Vt',\n",
       " '。/Sy']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/Data2_train_utf16.tag\", \"r\", encoding=\"utf-16\") as f:\n",
    "    data2 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = random.sample(data2, len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19374\n"
     ]
    }
   ],
   "source": [
    "empty_cnt = 0\n",
    "xs, ys, sts, ends = [], [], [], []\n",
    "for line in data2:\n",
    "    sent, label = get_sent(line), get_label(line)\n",
    "    st, end = get_se(sent, 300)    \n",
    "    if len(sent) == 0:\n",
    "        empty_cnt += 1\n",
    "        continue\n",
    "    xs.append(sent)\n",
    "    ys.append(label)\n",
    "    sts.append(st)\n",
    "    ends.append(end)\n",
    "print(empty_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_data(\"data/whole_train2.pkl\", xs, ys, sts, ends)\n",
    "# import pickle\n",
    "# with open(\"../gan-codebert/data/inputs.pkl\", \"rb\") as f:\n",
    "#     inputs, labels = pickle.load(f)\n",
    "train_rate = 0.7\n",
    "valid_rate = 0.8\n",
    "train_l = int(train_rate * len(xs))\n",
    "validl = int(valid_rate * len(xs))\n",
    "trainx, trainy, trainst, trainend = xs[:train_l], ys[:train_l], sts[:train_l], ends[:train_l]\n",
    "validx, validy, validst, validend = xs[train_l:validl], ys[train_l:validl], sts[train_l:validl], ends[train_l:validl]\n",
    "testx, testy, testst, testend = xs[validl:], ys[validl:], sts[validl:], ends[validl:]\n",
    "dump_data(\"data/train2.pkl\", trainx, trainy, trainst, trainend)\n",
    "dump_data(\"data/valid2.pkl\", validx, validy, validst, validend)\n",
    "dump_data(\"data/test2.pkl\", testx, testy, testst, testend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from model import POSModel, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    pass\n",
    "args = Args()\n",
    "args.pretrain_dir = \"hfl/chinese-roberta-wwm-ext\"\n",
    "args.device = torch.device(\"cuda\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "不論是為了保持香港的繁榮穩定和港人的生活方式不變，或是為了對中國的現代化及統一大業作出貢獻，全面落實「一國兩制」都是關鍵所在。\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'CcCcPcVtNgUsAnAnCcNcUsNcNcViSyCcPcPcNgUsVnCcVtNcVtNcSyAdVtSyNzSyDcVcNcNcSy'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train1.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = data[\"start\"]\n",
    "x = [\"\".join(l) for l in data[\"x\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = list(map(len, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'一位飽受雪卡毒素之苦的女士﹐埋怨衛生署的指引勸喻市民「每次進食小量」是不夠警惕性﹐因事實上食少少也會中毒。'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "np.max(arr)"
   ]
  }
 ]
}